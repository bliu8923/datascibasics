{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYPD Allegations\n",
    "* **See the main project notebook for instructions to be sure you satisfy the rubric!**\n",
    "* See Project 03 for information on the dataset.\n",
    "* A few example prediction questions to pursue are listed below. However, don't limit yourself to them!\n",
    "    * Predict the outcome of an allegation (might need to feature engineer your output column).\n",
    "    * Predict the complainant or officer ethnicity.\n",
    "    * Predict the amount of time between the month received vs month closed (difference of the two columns).\n",
    "    * Predict the rank of the officer.\n",
    "\n",
    "Be careful to justify what information you would know at the \"time of prediction\" and train your model using only those features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Findings\n",
    "\n",
    "\n",
    "### Introduction\n",
    "Is it possible to predict the current rank of the officer in the complaint based on other information about the allegation? This would be a classification problem, so we ended up using the .score() method of the DecisionTreeClassifier as our evaluation metric.\n",
    "\n",
    "### Baseline Model\n",
    "For the baseline model, we decided to do basic one-hot encoding for the categorical features, and just allowed quantitative columns to remain the same (scaling them seemed to diminish our accuracy by a small margin).\n",
    "\n",
    "#### Nominal Features\n",
    "Nominal features were the unique_mos_id(unique IDs for each officer), command_now, command_at_incident, mos_gender, mos_ethnicity, complainant_gender, complainant_ethnicity, board_disposition, allegation, and fado_type. We also wanted to clarify that for the baseline model, we included rank_at_incident as a nominal feature since we first believed that rank was another name for a job classification (i.e. a detective and an officer were just different jobs with different needs, not one above the other). We also cannot consider it as an ordinal feature since our prediction is being made on rank_now, which is supposedly ordinal but as a classification problem we cannot predict ordinal and must stick with these features being nominal. It would be counter intuitive to manipulate the y values of our model.\n",
    "\n",
    "#### Quantitative Features\n",
    "Quantitative features were the rest of the features, mainly ages of both the officer and complainant.\n",
    "\n",
    "In total, we used 10 nominal features and 3 quantitative features for a grand total of 13 features.\n",
    "\n",
    "#### Model Performance\n",
    "After training a model multiple times, we noticed that scores of our training data would average around 0.72-0.73 with a tree depth of 10, while scores with our test data would average 0.70-0.72, meaning that overall this was a pretty good model to begin with. There were a lot of features that we were excited to add on, however, given that there is still a pretty good room for improvement from this model. If these 13 features can allow for 70% of our predictions to be correct (considering that there is a pretty good spread of the types of ranks possible in the dataset), I would say that this model is pretty good given it's a baseline.\n",
    "\n",
    "### Final Model\n",
    "For the final model, we added a couple features that we thought would improve our chances of classifying the current rank of officers:\n",
    "#### Previous Number of Allegations\n",
    "An officer that gets a lot of allegations against them might be less likely to get a promotion since they are constantly caught up in other issues instead of performing well to get promoted. Additionally, an officer who is constantly being reported is likely doing something wrong. By using the unique_mos_id of each officer, we were able to replace that value with the number of allegations the officer had in the entire dataset.\n",
    "#### Change in Command\n",
    "An officer that changes precincts might also be more likely to get such a promotion, since changing precincts indicates instability in their previous environment that makes it difficult for promotion. Alternatively, an officer may be transferred to a precinct because there are disturbances taking place. This may present the officer with more opportunities for promotion in the new location. Of course, either of these could work against the officer and lead them to getting fewer promotions. There may also be an interpersonal element. Officers may work better around different people. It might also work the other way, in the case that an officer who does not work well with anyone would be transferred to a large number of precincts without a promotion at all. In any case, we believe this parameter to be relevant to the promotions an officer receives.\n",
    "#### Race Binarizer\n",
    "In society today and in the past, white people have had the structural and infrastructural advantage. By binarizing the officers into white and non-white people, we aimed to further accentuate the difference in treatment that they received. For example, we expect white officers to receive more promotions than non-white officers. We aimed to make it easier for the model to recognize this difference to give better accuracy to both populations.\n",
    "#### Age Bins\n",
    "We added this because we expect for age to correlate with promotion. The binning was done because we do not expect officers of minute age differences to receive vastly different treatments regarding promotions for good reason. By this, we mean that if 25 year olds receive a disproportionately high number of promotions compared to  24 or 26 year olds, we believe this to be the result of an outlier or a unique and rare case that happened to take place for those officers. We can limit the impact of such occurrences by binning the data, so that the burst of promotions is spread out among more officers. In the case that no such cases occur, minimal information should be lost anyway, since we are binning among frequent age groups. This way, the model will more easily develop a prediction of how age influences promotions in general.\n",
    " \n",
    "#### Model Type\n",
    "For our final model we chose to use a tree-model with max_depth=None, min_samples_leaf=2, min_samples_split=2. Through trial and error of classification models, we found that these parameters combined with the features we added gave us the best prediction values for our data.\n",
    "\n",
    "### Fairness Evaluation\n",
    "For our fairness evaluation, we looked at the officer's ethnicity (White vs POC) to see if there was any disparity between the model's predictions of rank between the two groups. As mentioned in our explanation of our binning feature, we found it important to ensure that the model was accurate for both white people and non-white people. As such, we used an accuracy parity in our permutation test.\n",
    "#### Null Hypothesis\n",
    "The model is equally accurate for both white officers and POC officers.\n",
    "    \n",
    "#### Alternate Hypothesis\n",
    "The model is more accurate for white officers compared to POC officers.\n",
    "\n",
    "#### Conclusion\n",
    "We used a significance value of Î±=0.05 for our test. After our test, we got a value of 0.015 which is well within the ranges of our histogram so we fail to reject the null hypothesis and accept that the model has parity between the accuracy of predicting promotions for white vs POC officers.\n",
    "\n",
    "### Appendix\n",
    "After extensive testing, we found that our values that come from the permutation test can vary by quite a large margin (even with values up to 0.4!). We determined that there was a possibility of white officers taking up a larger proportion of the training data in these instances during the train_test_split, which could account for the wide variety of our permutation test values (and therefore rejecting the null and accepting the alt). Due to this large difference in parity values, we will keep our conclusion the same but include this warning that there is a possibility for splits in the training data that will create large gaps of parity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'  # Higher resolution figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Police Officer            0.308712\n",
       "Detective                 0.297290\n",
       "Sergeant                  0.232358\n",
       "Lieutenant                0.110798\n",
       "Captain                   0.022034\n",
       "Deputy Inspector          0.013040\n",
       "Chiefs and other ranks    0.009353\n",
       "Inspector                 0.006415\n",
       "Name: rank_now, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = os.path.join('data', 'allegations_202007271729.csv')\n",
    "data = pd.read_csv(fp)\n",
    "data['rank_now'].value_counts()/len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Clean the Data\n",
    "base_data = data[[\n",
    "    'unique_mos_id',\n",
    "    'command_now',\n",
    "    'command_at_incident',\n",
    "    'rank_now',\n",
    "    'rank_incident',\n",
    "    'mos_gender',\n",
    "    'mos_ethnicity',\n",
    "    'mos_age_incident',\n",
    "    'complainant_ethnicity',\n",
    "    'complainant_age_incident',\n",
    "    'complainant_gender',\n",
    "    'board_disposition',\n",
    "    'allegation',\n",
    "    'fado_type'\n",
    "]].dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7298192486041449\n",
      "0.7139815471965933\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "#Seperate categorical and quantitiative columns, then one hot encode\n",
    "X = base_data.drop('rank_now', axis=1).reset_index()\n",
    "y = base_data['rank_now']\n",
    "types = X.dtypes\n",
    "cat_cols = types.loc[types == object].index\n",
    "quant_cols = types.loc[types != object].index\n",
    "cat_process = ('cat_processing', Pipeline([\n",
    "    ('one-hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "]),\n",
    "               cat_cols\n",
    "               )\n",
    "ct = ColumnTransformer([cat_process], remainder='passthrough')\n",
    "pl = Pipeline([('features', ct), ('classifier', DecisionTreeClassifier(max_depth=10))])\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X,y)\n",
    "pl.fit(Xtrain,ytrain)\n",
    "print(pl.score(Xtrain, ytrain))\n",
    "print(pl.score(Xtest, ytest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_mos_id</th>\n",
       "      <th>command_now</th>\n",
       "      <th>command_at_incident</th>\n",
       "      <th>rank_now</th>\n",
       "      <th>rank_incident</th>\n",
       "      <th>mos_gender</th>\n",
       "      <th>mos_ethnicity</th>\n",
       "      <th>mos_age_incident</th>\n",
       "      <th>complainant_ethnicity</th>\n",
       "      <th>complainant_age_incident</th>\n",
       "      <th>complainant_gender</th>\n",
       "      <th>board_disposition</th>\n",
       "      <th>allegation</th>\n",
       "      <th>fado_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10004</td>\n",
       "      <td>078 PCT</td>\n",
       "      <td>078 PCT</td>\n",
       "      <td>Police Officer</td>\n",
       "      <td>Police Officer</td>\n",
       "      <td>M</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>32</td>\n",
       "      <td>Black</td>\n",
       "      <td>38.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Substantiated (Command Lvl Instructions)</td>\n",
       "      <td>Failure to provide RTKA card</td>\n",
       "      <td>Abuse of Authority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10007</td>\n",
       "      <td>078 PCT</td>\n",
       "      <td>PBBS</td>\n",
       "      <td>Police Officer</td>\n",
       "      <td>Police Officer</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>24</td>\n",
       "      <td>Black</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Substantiated (Charges)</td>\n",
       "      <td>Action</td>\n",
       "      <td>Discourtesy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10007</td>\n",
       "      <td>078 PCT</td>\n",
       "      <td>PBBS</td>\n",
       "      <td>Police Officer</td>\n",
       "      <td>Police Officer</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>24</td>\n",
       "      <td>Black</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Substantiated (Charges)</td>\n",
       "      <td>Race</td>\n",
       "      <td>Offensive Language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10007</td>\n",
       "      <td>078 PCT</td>\n",
       "      <td>PBBS</td>\n",
       "      <td>Police Officer</td>\n",
       "      <td>Police Officer</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>25</td>\n",
       "      <td>Black</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Substantiated (Charges)</td>\n",
       "      <td>Question</td>\n",
       "      <td>Abuse of Authority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10012</td>\n",
       "      <td>078 PCT</td>\n",
       "      <td>078 PCT</td>\n",
       "      <td>Sergeant</td>\n",
       "      <td>Sergeant</td>\n",
       "      <td>F</td>\n",
       "      <td>Black</td>\n",
       "      <td>50</td>\n",
       "      <td>White</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Substantiated (Command Lvl Instructions)</td>\n",
       "      <td>Refusal to process civilian complaint</td>\n",
       "      <td>Abuse of Authority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33353</th>\n",
       "      <td>9992</td>\n",
       "      <td>078 PCT</td>\n",
       "      <td>066 PCT</td>\n",
       "      <td>Sergeant</td>\n",
       "      <td>Police Officer</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>36</td>\n",
       "      <td>Asian</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Unsubstantiated</td>\n",
       "      <td>Word</td>\n",
       "      <td>Discourtesy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33354</th>\n",
       "      <td>9992</td>\n",
       "      <td>078 PCT</td>\n",
       "      <td>066 PCT</td>\n",
       "      <td>Sergeant</td>\n",
       "      <td>Police Officer</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>36</td>\n",
       "      <td>Asian</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Unsubstantiated</td>\n",
       "      <td>Interference with recording</td>\n",
       "      <td>Abuse of Authority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33355</th>\n",
       "      <td>9992</td>\n",
       "      <td>078 PCT</td>\n",
       "      <td>066 PCT</td>\n",
       "      <td>Sergeant</td>\n",
       "      <td>Police Officer</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>36</td>\n",
       "      <td>Asian</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Substantiated (Formalized Training)</td>\n",
       "      <td>Search (of person)</td>\n",
       "      <td>Abuse of Authority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33356</th>\n",
       "      <td>9992</td>\n",
       "      <td>078 PCT</td>\n",
       "      <td>066 PCT</td>\n",
       "      <td>Sergeant</td>\n",
       "      <td>Police Officer</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>36</td>\n",
       "      <td>Asian</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Substantiated (Formalized Training)</td>\n",
       "      <td>Vehicle search</td>\n",
       "      <td>Abuse of Authority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33357</th>\n",
       "      <td>9992</td>\n",
       "      <td>078 PCT</td>\n",
       "      <td>066 PCT</td>\n",
       "      <td>Sergeant</td>\n",
       "      <td>Police Officer</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>36</td>\n",
       "      <td>Asian</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Substantiated (Formalized Training)</td>\n",
       "      <td>Frisk</td>\n",
       "      <td>Abuse of Authority</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28179 rows Ã 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       unique_mos_id command_now command_at_incident        rank_now  \\\n",
       "0              10004     078 PCT             078 PCT  Police Officer   \n",
       "1              10007     078 PCT                PBBS  Police Officer   \n",
       "2              10007     078 PCT                PBBS  Police Officer   \n",
       "3              10007     078 PCT                PBBS  Police Officer   \n",
       "5              10012     078 PCT             078 PCT        Sergeant   \n",
       "...              ...         ...                 ...             ...   \n",
       "33353           9992     078 PCT             066 PCT        Sergeant   \n",
       "33354           9992     078 PCT             066 PCT        Sergeant   \n",
       "33355           9992     078 PCT             066 PCT        Sergeant   \n",
       "33356           9992     078 PCT             066 PCT        Sergeant   \n",
       "33357           9992     078 PCT             066 PCT        Sergeant   \n",
       "\n",
       "        rank_incident mos_gender mos_ethnicity  mos_age_incident  \\\n",
       "0      Police Officer          M      Hispanic                32   \n",
       "1      Police Officer          M         White                24   \n",
       "2      Police Officer          M         White                24   \n",
       "3      Police Officer          M         White                25   \n",
       "5            Sergeant          F         Black                50   \n",
       "...               ...        ...           ...               ...   \n",
       "33353  Police Officer          M         White                36   \n",
       "33354  Police Officer          M         White                36   \n",
       "33355  Police Officer          M         White                36   \n",
       "33356  Police Officer          M         White                36   \n",
       "33357  Police Officer          M         White                36   \n",
       "\n",
       "      complainant_ethnicity  complainant_age_incident complainant_gender  \\\n",
       "0                     Black                      38.0             Female   \n",
       "1                     Black                      26.0               Male   \n",
       "2                     Black                      26.0               Male   \n",
       "3                     Black                      45.0               Male   \n",
       "5                     White                      31.0               Male   \n",
       "...                     ...                       ...                ...   \n",
       "33353                 Asian                      21.0               Male   \n",
       "33354                 Asian                      21.0               Male   \n",
       "33355                 Asian                      21.0               Male   \n",
       "33356                 Asian                      21.0               Male   \n",
       "33357                 Asian                      21.0               Male   \n",
       "\n",
       "                              board_disposition  \\\n",
       "0      Substantiated (Command Lvl Instructions)   \n",
       "1                       Substantiated (Charges)   \n",
       "2                       Substantiated (Charges)   \n",
       "3                       Substantiated (Charges)   \n",
       "5      Substantiated (Command Lvl Instructions)   \n",
       "...                                         ...   \n",
       "33353                           Unsubstantiated   \n",
       "33354                           Unsubstantiated   \n",
       "33355       Substantiated (Formalized Training)   \n",
       "33356       Substantiated (Formalized Training)   \n",
       "33357       Substantiated (Formalized Training)   \n",
       "\n",
       "                                  allegation           fado_type  \n",
       "0               Failure to provide RTKA card  Abuse of Authority  \n",
       "1                                     Action         Discourtesy  \n",
       "2                                       Race  Offensive Language  \n",
       "3                                   Question  Abuse of Authority  \n",
       "5      Refusal to process civilian complaint  Abuse of Authority  \n",
       "...                                      ...                 ...  \n",
       "33353                                   Word         Discourtesy  \n",
       "33354            Interference with recording  Abuse of Authority  \n",
       "33355                     Search (of person)  Abuse of Authority  \n",
       "33356                         Vehicle search  Abuse of Authority  \n",
       "33357                                  Frisk  Abuse of Authority  \n",
       "\n",
       "[28179 rows x 14 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Clean the Data\n",
    "final_data = data[['unique_mos_id', 'command_now', 'command_at_incident', 'rank_now', 'rank_incident', 'mos_gender', 'mos_ethnicity', 'mos_age_incident', 'complainant_ethnicity', 'complainant_age_incident', 'complainant_gender', 'board_disposition', 'allegation', 'fado_type']].dropna(how='any')\n",
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class AllegationNum(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.grps_ = {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        for x in X.unique_mos_id.unique():\n",
    "            self.grps_[x] = len(X[(X.loc[:,'unique_mos_id'] == x)])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "\n",
    "        try:\n",
    "            getattr(self, \"grps_\")\n",
    "        except AttributeError:\n",
    "            raise RuntimeError(\"You must fit the transformer before tranforming the data!\")\n",
    "\n",
    "        # X may not be a dataframe (e.g. np.array)\n",
    "        df = X\n",
    "        df.loc[:,'unique_mos_id'] = df.loc[:,'unique_mos_id'].replace(self.grps_)\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9441657991861455\n",
      "0.9067423704755145\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "def rank_check(X):\n",
    "    return pd.DataFrame(X.iloc[:,0] == X.iloc[:,1])\n",
    "def racehelper(x):\n",
    "    #print(type(x))\n",
    "    series= x.apply(lambda c: 1 if c==\"White\" else 0)\n",
    "    return series.to_frame(name=\"complainant_ethnicity\")\n",
    "def binhelper(x):\n",
    "    return pd.DataFrame(pd.cut(x, bins=5, labels=False))\n",
    "\n",
    "#Seperate categorical and quantitiative columns, then one hot encode\n",
    "X = final_data.drop('rank_now', axis=1).reset_index()\n",
    "y = final_data['rank_now']\n",
    "rank = FunctionTransformer(rank_check)\n",
    "agebin=FunctionTransformer(binhelper)\n",
    "racebinary=FunctionTransformer(racehelper)\n",
    "types = X.dtypes\n",
    "cat_cols = types.loc[types == object].index\n",
    "quant_cols = types.loc[types != object].index\n",
    "cat_process = ('cat_processing', Pipeline([('one-hot', OneHotEncoder(handle_unknown='ignore'))]),cat_cols)\n",
    "quan_process = ('qua_processing', Pipeline([('scaler', StandardScaler())]), quant_cols)\n",
    "cat_process2 = (\"yep\", Pipeline([(\"race\",racebinary)]),\"complainant_ethnicity\")\n",
    "cat_process3 = (\"yep2\", Pipeline([(\"race\",agebin)]),\"complainant_age_incident\")\n",
    "ct = ColumnTransformer([cat_process2, cat_process3, cat_process, quan_process], remainder='passthrough')\n",
    "pl = Pipeline([('allegations', AllegationNum()), ('features', ct), ('classifier', DecisionTreeClassifier(min_samples_leaf=2, min_samples_split=2))])\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X,y)\n",
    "pl.fit(Xtrain,ytrain)\n",
    "print(pl.score(Xtrain, ytrain))\n",
    "print(pl.score(Xtest, ytest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'max_depth': [2, 5, 10, 15, 18, None],\n",
       "                         'min_samples_leaf': [2, 5, 10, 15, 20],\n",
       "                         'min_samples_split': [2, 5, 10, 15, 20]})"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X,y)\n",
    "pl.fit(Xtrain,ytrain)\n",
    "parameters = {\n",
    "    'max_depth':[2,5,10,15,18,None],\n",
    "    'min_samples_split':[2,5,10,15,20],\n",
    "    'min_samples_leaf':[2,5,10,15,20]\n",
    "}\n",
    "clf = GridSearchCV(DecisionTreeClassifier(), parameters)\n",
    "Xtrain = pl.named_steps['features'].transform(Xtrain)\n",
    "clf.fit(Xtrain, ytrain)\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fairness Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_data=base_data[base_data[\"mos_ethnicity\"]==\"White\"]\n",
    "poc_data=base_data[base_data[\"mos_ethnicity\"]!=\"White\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Perm Test'}, ylabel='Frequency'>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 263,
       "width": 388
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = final_data.drop('rank_now', axis=1)\n",
    "y = final_data['rank_now']\n",
    "\n",
    "rank = FunctionTransformer(rank_check)\n",
    "agebin=FunctionTransformer(binhelper)\n",
    "racebinary=FunctionTransformer(racehelper)\n",
    "types = X.dtypes\n",
    "cat_cols = types.loc[types == object].index\n",
    "quant_cols = types.loc[types != object].index\n",
    "cat_process = ('cat_processing', Pipeline([('one-hot', OneHotEncoder(handle_unknown='ignore'))]),cat_cols)\n",
    "quan_process = ('qua_processing', Pipeline([('scaler', StandardScaler())]), quant_cols)\n",
    "comm_process = ('comm', Pipeline([('comm_check', rank)]), [\"command_at_incident\", \"command_now\"])\n",
    "cat_process2 = (\"yep\", Pipeline([(\"race\",racebinary)]),\"complainant_ethnicity\")\n",
    "cat_process3 = (\"yep2\", Pipeline([(\"race\",agebin)]),\"complainant_age_incident\")\n",
    "ct = ColumnTransformer([comm_process, cat_process2, cat_process3, cat_process, quan_process], remainder='passthrough')\n",
    "pl = Pipeline([('allegations', AllegationNum()), ('features', ct), ('classifier', DecisionTreeClassifier(max_depth=10))])\n",
    "#pl = Pipeline([('features', ct), ('classifier', DecisionTreeClassifier(max_depth=10))])\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X,y)\n",
    "pl.fit(Xtrain,ytrain)\n",
    "preds = pl.predict(Xtest)\n",
    "results = Xtest\n",
    "results['prediction'] = preds\n",
    "results['rank_now'] = ytest\n",
    "results['is_white'] = (results.mos_ethnicity == 'White').replace({True:'White', False:\"POC\"})\n",
    "obs = results.groupby('is_white').apply(lambda x: metrics.accuracy_score(x.rank_now, x.prediction)).diff().iloc[-1]\n",
    "stats = []\n",
    "for _ in range(1000):\n",
    "    s = (\n",
    "        results[['is_white', 'prediction', 'rank_now']]\n",
    "        .assign(is_white=results.is_white.sample(frac=1.0, replace=False).reset_index(drop=True))\n",
    "        .groupby('is_white')\n",
    "        .apply(lambda x: metrics.accuracy_score(x.rank_now, x.prediction))\n",
    "        .diff()\n",
    "        .iloc[-1]\n",
    "    )\n",
    "    stats.append(s)\n",
    "\n",
    "print(pd.Series(stats <= obs).mean())\n",
    "pd.Series(stats).plot(kind='hist', title='Perm Test')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
